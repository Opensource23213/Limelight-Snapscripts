package org.firstinspires.ftc.teamcode.drive.opmode;

import static org.firstinspires.ftc.teamcode.drive.opmode.CleanCode.VisionPipeline.*;

import com.qualcomm.robotcore.eventloop.opmode.LinearOpMode;
import com.qualcomm.robotcore.eventloop.opmode.TeleOp;

import org.firstinspires.ftc.robotcore.external.hardware.camera.WebcamName;
import org.opencv.core.*;
import org.opencv.imgproc.Imgproc;
import org.opencv.imgproc.Moments;
import org.openftc.easyopencv.*;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;

@TeleOp(name="VisionOpMode", group="Vision")
public class CleanCode extends LinearOpMode {

    OpenCvCamera camera;
    VisionPipeline pipeline;

    @Override
    public void runOpMode() {

        int cameraMonitorViewId = hardwareMap.appContext.getResources().getIdentifier(
                "cameraMonitorViewId", "id", hardwareMap.appContext.getPackageName());
        camera = OpenCvCameraFactory.getInstance().createWebcam(
                hardwareMap.get(WebcamName.class, "Webcam 1"), cameraMonitorViewId);
        pipeline = new VisionPipeline();
        camera.setPipeline(pipeline);

        camera.openCameraDeviceAsync(new OpenCvCamera.AsyncCameraOpenListener() {
            @Override
            public void onOpened() {

                camera.startStreaming(VisionPipeline.IMAGE_WIDTH, VisionPipeline.IMAGE_HEIGHT, OpenCvCameraRotation.UPRIGHT);
            }

            @Override
            public void onError(int errorCode) {
                telemetry.addData("Camera Error", errorCode);
                telemetry.update();
            }
        });

        waitForStart();

        while (opModeIsActive()) {
            // Example usage: you can get info from pipeline's public fields here

            telemetry.addData("Largest Contour Area", pipeline.largestArea);
            telemetry.addData("Valid Contours Found", pipeline.validContours.size());
            telemetry.update();
            sleep(50);
        }

    }

    public class VisionPipeline extends OpenCvPipeline {

        // Constants for filtering contours
        public static final double SMALL_CONTOUR_AREA = 100;
        public List<Double> newerpython = new ArrayList<>();
        // Minimum average brightness threshold (0-255)
        public static final double MIN_BRIGHTNESS_THRESHOLD = 0;
        public static final double hue_low = 0;
        public static final double hue_high = 50;
        public static final double sat_low = 100;
        public static final double sat_high = 255;
        public static final double value_low = 0;
        public static final double value_high = 255;

        // Color detection ranges for yellow in HSV
        public Scalar HSV_YELLOW_LOWER = new Scalar(hue_low, sat_low, value_low);
        public Scalar HSV_YELLOW_UPPER = new Scalar(hue_high, sat_high, value_high);

        // Edge detection parameters - initial values
        public static final int BLUR_SIZE = 17;
        public static final int SOBEL_KERNEL = 3;

        // Aspect ratio range for contour filtering
        public static final double MIN_ASPECT_RATIO = 0;
        public static final double MAX_ASPECT_RATIO = 100;

        // Vertical position threshold (in pixels from bottom)
        public static final int VERTICAL_THRESHOLD = 800;

        public static final double VERTICAL_ANGLE = 45; // degrees downward from horizontal (subtract from 90 if it doesn't work)
        public static final double HORIZONTAL_ANGLE = 0; // degrees right
        public static final double CAMERA_HEIGHT = 20; // inches/meters/millimeters (doesn't matter, either one works)
        public static final int IMAGE_WIDTH = 640; // pixels (standard for limelight)
        public static final int IMAGE_HEIGHT = 480; // pixels (standard for limelight)
        public static final double HFOV = 54.5; //# degrees (standard for limelight)
        public static final double VFOV = 42.0; //# degrees (standard for limelight)
        public static final double Camera_xOffset = 0; //# left is positive
        public static final double Camera_yOffset = 0; //# forward is positive
        public static final double Max_x = 99; //# furthest left you want to see in inches/meters/millimeters
        public static final double Min_x = 99; //# furthest right you want to see in inches/meters/millimeters
        public static final double Max_y = 99; //# furthest forward you want to see in inches/meters/millimeters
        public static final double Min_y = 0; //# furthest back you want to see in inches/meters/millimeters

        // Outputs / State from last frame
        public List<ContourInfo> validContours = new ArrayList<>();
        public double largestArea = 0;

        // Helper class for contour info
        public class ContourInfo {
            public MatOfPoint contour;
            public Point center;
            public double angle;
            public double area;
            public int index;

            public ContourInfo(MatOfPoint contour, Point center, double angle, double area, int index) {
                this.contour = contour;
                this.center = center;
                this.angle = angle;
                this.area = area;
                this.index = index;
            }
        }

        // Converts pixel (x_pix, y_pix) to ground coordinates relative to camera
        public double[] pixelToGroundCoords(double x_pix, double y_pix) {

            double fx = IMAGE_WIDTH / (2.0 * Math.tan(Math.toRadians(HFOV / 2.0)));
            double fy = IMAGE_HEIGHT / (2.0 * Math.tan(Math.toRadians(VFOV / 2.0)));
            double cx = IMAGE_WIDTH / 2.0;
            double cy = IMAGE_HEIGHT / 2.0;

            double x_cam = (x_pix - cx) / fx;
            double y_cam = (y_pix - cy) / fy;
            double z_cam = 1.0;

            double norm = Math.sqrt(x_cam * x_cam + y_cam * y_cam + z_cam * z_cam);
            x_cam /= norm;
            y_cam /= norm;
            z_cam /= norm;

            double pitch = Math.toRadians(VERTICAL_ANGLE);
            double yaw = Math.toRadians(HORIZONTAL_ANGLE);

            // Rotation around X (pitch)
            double y_rot = y_cam * Math.cos(pitch) - z_cam * Math.sin(pitch);
            double z_rot = y_cam * Math.sin(pitch) + z_cam * Math.cos(pitch);

            // Rotation around Y (yaw)
            double x_world = x_cam * Math.cos(yaw) + z_rot * Math.sin(yaw);
            double y_world = y_rot;
            double z_world = -x_cam * Math.sin(yaw) + z_rot * Math.cos(yaw);

            double t = -CAMERA_HEIGHT / z_world;

            double x_ground = t * x_world;
            double y_ground = t * y_world;

            // Unrotate yaw
            double X_corrected = x_ground * Math.cos(-yaw) + z_world * Math.sin(-yaw);
            double Y_corrected = y_ground;

            return new double[]{X_corrected, Y_corrected};
        }

        // Calculate angle of contour using fitEllipse
        public double calculateAngle(MatOfPoint contour) {
            if (contour.toArray().length < 5) {
                return 0;
            }
            MatOfPoint2f contour2f = new MatOfPoint2f(contour.toArray());
            RotatedRect ellipse = Imgproc.fitEllipse(contour2f);
            return ellipse.angle;
        }

        // Draw info text and lines on frame
        public void drawInfo(Mat image, String color, double angle, Point center, double centerx, double centery, int index, double area) {
            Imgproc.putText(image, "#" + index + ": " + color, new Point(center.x - 40, center.y - 60), Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0, 255, 0), 2);
            Imgproc.putText(image, String.format("Angle: %.2f", angle), new Point(center.x - 40, center.y - 40), Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0, 255, 0), 2);
            Imgproc.putText(image, String.format("Center: %.2f %.2f", centerx, centery), new Point(center.x - 40, center.y - 20), Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0, 255, 0), 2);
            Imgproc.circle(image, center, 5, new Scalar(0, 255, 0), -1);
            Point lineEnd = new Point(center.x + 50 * Math.cos(Math.toRadians(90 - angle)),
                    center.y - 50 * Math.sin(Math.toRadians(90 - angle)));
            Imgproc.line(image, center, lineEnd, new Scalar(0, 255, 0), 2);
        }

        // Separate touching contours (approximated)
        public List<MatOfPoint> separateTouchingContours(MatOfPoint contour, double minAreaRatio) {
            Rect boundingRect = Imgproc.boundingRect(contour);

            Mat mask = new Mat();
            Mat distTransform = new Mat();
            Mat thresh = new Mat();
            Mat hierarchy = new Mat();
            List<MatOfPoint> resultContours = new ArrayList<>();

            try {
                mask = Mat.zeros(boundingRect.height, boundingRect.width, CvType.CV_8UC1);

                // Shift contour into local mask coordinates
                Point[] pts = contour.toArray();
                Point[] shiftedPts = new Point[pts.length];
                for (int i = 0; i < pts.length; i++) {
                    shiftedPts[i] = new Point(pts[i].x - boundingRect.x, pts[i].y - boundingRect.y);
                }
                MatOfPoint shiftedContour = new MatOfPoint(shiftedPts);

                Imgproc.drawContours(mask, Arrays.asList(shiftedContour), -1, new Scalar(255), -1);

                double originalArea = Imgproc.contourArea(contour);

                Imgproc.distanceTransform(mask, distTransform, Imgproc.DIST_L2, 3);

                for (double threshold = 0.10; threshold <= 0.90; threshold += 0.10) {
                    Mat currentThresh = new Mat();
                    try {
                        Imgproc.threshold(distTransform, currentThresh, threshold * Core.minMaxLoc(distTransform).maxVal, 255, Imgproc.THRESH_BINARY);
                        currentThresh.convertTo(currentThresh, CvType.CV_8U);

                        List<MatOfPoint> contours = new ArrayList<>();
                        hierarchy = new Mat();
                        Imgproc.findContours(currentThresh, contours, hierarchy, Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);

                        List<MatOfPoint> validContours = new ArrayList<>();
                        for (MatOfPoint c : contours) {
                            if (Imgproc.contourArea(c) > originalArea * minAreaRatio) {
                                validContours.add(c);
                            }
                        }

                        if (validContours.size() > resultContours.size()) {
                            resultContours = validContours;
                        }
                    } finally {
                        currentThresh.release();
                    }
                }

                if (!resultContours.isEmpty()) {
                    List<MatOfPoint> translatedContours = new ArrayList<>();
                    for (MatOfPoint c : resultContours) {
                        Point[] points = c.toArray();
                        for (Point p : points) {
                            p.x += boundingRect.x;
                            p.y += boundingRect.y;
                        }
                        MatOfPoint translated = new MatOfPoint();
                        translated.fromArray(points);
                        translatedContours.add(translated);
                    }
                    return translatedContours;
                }

                return Arrays.asList(contour);
            } finally {
                mask.release();
                distTransform.release();
                thresh.release();
                hierarchy.release();
            }
        }


        // Process color mask to extract edges and contours
        public class ProcessColorResult {
            public List<MatOfPoint> contours;
            public Mat hierarchy;
            public Mat grayMasked;
            public boolean isDebug;
            public Mat debugInfo;

            public ProcessColorResult(List<MatOfPoint> contours, Mat hierarchy, Mat grayMasked, boolean isDebug, Mat debugInfo) {
                this.contours = contours;
                this.hierarchy = hierarchy;
                this.grayMasked = grayMasked;
                this.isDebug = isDebug;
                this.debugInfo = debugInfo;
            }
        }

        public ProcessColorResult processColor(Mat frame, Mat mask) {
            Mat kernel = null;
            Mat maskedFrame = new Mat();
            Mat grayMasked = new Mat();
            Mat grayBoosted = new Mat();
            Mat blurred = new Mat();
            Mat sobelX = new Mat();
            Mat sobelY = new Mat();
            Mat magnitude = new Mat();
            Mat edges = new Mat();
            Mat hierarchy = new Mat();

            try {
                kernel = Imgproc.getStructuringElement(Imgproc.MORPH_RECT, new Size(5, 5));
                Core.bitwise_and(frame, frame, maskedFrame, mask);

                Imgproc.cvtColor(maskedFrame, grayMasked, Imgproc.COLOR_BGR2GRAY);

                Core.addWeighted(grayMasked, 1.5, mask, 0.5, 0, grayBoosted);

                Imgproc.GaussianBlur(grayBoosted, blurred, new Size(3, 3), 0);

                Imgproc.Sobel(blurred, sobelX, CvType.CV_32F, 1, 0, 1);
                Imgproc.Sobel(blurred, sobelY, CvType.CV_32F, 0, 1, 1);

                Core.magnitude(sobelX, sobelY, magnitude);
                Core.normalize(magnitude, magnitude, 0, 255, Core.NORM_MINMAX);

                Mat magnitude_8u = new Mat();
                magnitude.convertTo(magnitude_8u, CvType.CV_8UC1);
                Imgproc.threshold(magnitude, edges, 50, 255, Imgproc.THRESH_BINARY);
                magnitude_8u.release();

                Core.bitwise_not(edges, edges);
                Core.bitwise_and(edges, edges, edges, mask);
                Imgproc.GaussianBlur(edges, edges, new Size(3, 3), 0);
                edges.convertTo(edges, CvType.CV_8UC1);
                List<MatOfPoint> contours = new ArrayList<>();
                Imgproc.findContours(edges, contours, hierarchy, Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);

                return new ProcessColorResult(contours, hierarchy, grayMasked.clone(), false, null);
            } finally {
                if (kernel != null) kernel.release();
                maskedFrame.release();
                grayBoosted.release();
                blurred.release();
                sobelX.release();
                sobelY.release();
                magnitude.release();
                edges.release();
                // grayMasked is intentionally returned; do not release here
                // hierarchy is also returned, release only if not used outside
                // hierarchy is returned, but cloned if needed externally
                // if not used outside, uncomment: hierarchy.release();
            }
        }

        @Override
        public Mat processFrame(Mat frame) {
            Mat hsv = new Mat();
            Mat hsvDenoised = new Mat();
            Mat yellowMask = new Mat();
            Mat contourFrame = frame.clone(); // For drawing
            List<MatOfPoint> separatedContours;

            try {
                Imgproc.cvtColor(frame, hsv, Imgproc.COLOR_BGR2HSV);
                Imgproc.GaussianBlur(hsv, hsvDenoised, new Size(5, 5), 0);

                Core.inRange(hsvDenoised, HSV_YELLOW_LOWER, HSV_YELLOW_UPPER, yellowMask);

                Imgproc.erode(yellowMask, yellowMask, Imgproc.getStructuringElement(Imgproc.MORPH_RECT, new Size(3, 3)));


                List<MatOfPoint> contours = new ArrayList<>();
                Mat hierarchy = new Mat();
                Imgproc.findContours(yellowMask, contours, hierarchy, Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);

                telemetry.addData("Contours Found", contours.size());

                validContours.clear();
                largestArea = 0;

                for (int i = 0; i < contours.size(); i++) {
                    MatOfPoint contour = contours.get(i);
                    double area = Imgproc.contourArea(contour);
                    if (area < SMALL_CONTOUR_AREA) continue;

                    RotatedRect rect = Imgproc.minAreaRect(new MatOfPoint2f(contour.toArray()));
                    double width = Math.max(rect.size.width, rect.size.height);
                    double height = Math.min(rect.size.width, rect.size.height);
                    if (width == 0 || height == 0) continue;

                    double aspectRatio = width / height;
                    if (aspectRatio < MIN_ASPECT_RATIO || aspectRatio > MAX_ASPECT_RATIO) continue;

                    separatedContours = separateTouchingContours(contour, 0.2); // Your function used here

                    for (MatOfPoint sepContour : separatedContours) {
                        Mat mask = Mat.zeros(yellowMask.size(), CvType.CV_8UC1);
                        Imgproc.drawContours(mask, Collections.singletonList(sepContour), -1, new Scalar(255), -1);

                        Scalar meanScalar = Core.mean(yellowMask, mask); // use mask for brightness check
                        if (meanScalar.val[0] < MIN_BRIGHTNESS_THRESHOLD) continue;

                        Moments M = Imgproc.moments(sepContour);
                        if (M.get_m00() == 0) continue;

                        Point center = new Point(M.get_m10() / M.get_m00(), M.get_m01() / M.get_m00());
                        if (center.y < frame.height() - VERTICAL_THRESHOLD) continue;

                        double angle = calculateAngle(sepContour);

                        validContours.add(new ContourInfo(sepContour, center, angle, area, i));
                    }
                }

                List<double[]> newpython = new ArrayList<>();
                for (ContourInfo contourInfo : validContours) {
                    double[] thingy = {contourInfo.center.x, contourInfo.center.y, contourInfo.angle};
                    double[] groundCoords = pixelToGroundCoords(thingy[0], thingy[1]);
                    groundCoords[1] += Camera_yOffset;
                    groundCoords[0] += Camera_xOffset;
                    double[] adjusted = new double[]{groundCoords[0], groundCoords[1], contourInfo.angle};

                    int place = 0;
                    for (int j = 0; j < newpython.size(); j++) {
                        if (newpython.get(j)[1] < adjusted[1]) place++;
                        else break;
                    }
                    newpython.add(place, adjusted);

                    Imgproc.drawContours(contourFrame, Collections.singletonList(contourInfo.contour), -1, new Scalar(0, 255, 0), 2);
                    drawInfo(contourFrame, "Block", contourInfo.angle, contourInfo.center, groundCoords[0], groundCoords[1], contourInfo.index + 1, contourInfo.area);
                }

                for (double[] arr : newpython) {
                    for (double v : arr) newerpython.add(v);
                }

                telemetry.addData("Valid Contours", validContours.size());
                telemetry.update();

                return contourFrame;

            } catch (Exception e) {
                telemetry.addData("Error", e.getMessage());
                telemetry.update();
                return frame;
            } finally {
                hsv.release();
                hsvDenoised.release();
                yellowMask.release();
            }
        }

    }
}
