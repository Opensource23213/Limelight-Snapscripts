import cv2
import numpy as np
import math
import time
from collections import defaultdict

# Track OpenCV function calls and timing
# opencv_stats = defaultdict(lambda: {'count': 0, 'total_time': 0})

# def track_opencv(func_name):
#     def decorator(func):
#         def wrapper(*args, **kwargs):
#             start = time.time()
#             result = func(*args, **kwargs)
#             end = time.time()
#             opencv_stats[func_name]['count'] += 1
#             opencv_stats[func_name]['total_time'] += (end - start)
#             return result
#         return wrapper
#     return decorator

# Wrap commonly used OpenCV functions
# cv2.split = track_opencv('split')(cv2.split)
# cv2.cvtColor = track_opencv('cvtColor')(cv2.cvtColor)
# cv2.inRange = track_opencv('inRange')(cv2.inRange)
# cv2.bitwise_and = track_opencv('bitwise_and')(cv2.bitwise_and)
# cv2.bitwise_or = track_opencv('bitwise_or')(cv2.bitwise_or)
# cv2.bitwise_not = track_opencv('bitwise_not')(cv2.bitwise_not)
# cv2.morphologyEx = track_opencv('morphologyEx')(cv2.morphologyEx)
# cv2.GaussianBlur = track_opencv('GaussianBlur')(cv2.GaussianBlur)
# cv2.Sobel = track_opencv('Sobel')(cv2.Sobel)
# cv2.Canny = track_opencv('Canny')(cv2.Canny)
# cv2.findContours = track_opencv('findContours')(cv2.findContours)
# cv2.drawContours = track_opencv('drawContours')(cv2.drawContours)
# cv2.bilateralFilter = track_opencv('bilateralFilter')(cv2.bilateralFilter)
# cv2.normalize = track_opencv('normalize')(cv2.normalize)
# cv2.dilate = track_opencv('dilate')(cv2.dilate)
# cv2.contourArea = track_opencv('contourArea')(cv2.contourArea)

# Constants for filtering contours
SMALL_CONTOUR_AREA = 1000

# Minimum average brightness threshold (0-255)
MIN_BRIGHTNESS_THRESHOLD = 0

# Color detection ranges for red in HSV
HSV_RED_RANGE_1 = ([0, 50, 80], [10, 255, 255])  # Lower red range
HSV_RED_RANGE_2 = ([170, 50, 80], [255, 255, 255])  # Upper red range

# Edge detection parameters - initial values
BLUR_SIZE = 17
SOBEL_KERNEL = 3

# Aspect ratio range for contour filtering
MIN_ASPECT_RATIO = 0  # Minimum width/height ratio
MAX_ASPECT_RATIO = 6.0  # Maximum width/height ratio


VERTICAL_ANGLE = 0            # degrees downward from horizontal (subtract from 90 if it doesn't work)
HORIZONTAL_ANGLE = 0         # degrees right
CAMERA_HEIGHT = 0          # inches/meters/millimeters (doesn't matter, either one works)
IMAGE_WIDTH = 640              # pixels (standard for limelight)
IMAGE_HEIGHT = 480             # pixels (standard for limelight)
HFOV = 54.5                    # degrees (standard for limelight)
VFOV = 42.0                    # degrees (standard for limelight)
Camera_xOffset = 0             # left is positive
Camera_yOffset = 0             # forward is positive
Max_x = 99                     # furthest left you want to see in inches/meters/millimeters
Min_x = 99                     # furthest right you want to see in inches/meters/millimeters
Max_y = 99                     # furthest forward you want to see in inches/meters/millimeters
Min_y = 0                      # furthest back you want to see in inches/meters/millimeters

def pixel_to_ground_coords(x_pix, y_pix):
    """
    Converts pixel (x_pix, y_pix) to (X, Y) in meters relative to the camera's forward direction.
    - X: horizontal (left/right)
    - Y: forward (away from camera)
    """

    # Step 1: Focal lengths in pixels
    fx = IMAGE_WIDTH / (2 * math.tan(math.radians(HFOV) / 2))
    fy = IMAGE_HEIGHT / (2 * math.tan(math.radians(VFOV) / 2))
    cx = IMAGE_WIDTH / 2
    cy = IMAGE_HEIGHT / 2

    # Step 2: Ray in camera space (standard pinhole projection)
    x_cam = (x_pix - cx) / fx     # right is positive
    y_cam = (y_pix - cy) / fy     # down is positive
    z_cam = 1.0                   # forward

    ray = np.array([x_cam, y_cam, z_cam])
    ray /= np.linalg.norm(ray)

    # Step 3: Apply camera rotation (pitch first, then yaw)
    pitch = math.radians(VERTICAL_ANGLE)     # tilt downward
    yaw = math.radians(HORIZONTAL_ANGLE)     # turn right

    # Rotation around X (pitch, downward tilt)
    Rx = np.array([
        [1, 0, 0],
        [0, math.cos(pitch), -math.sin(pitch)],
        [0, math.sin(pitch),  math.cos(pitch)]
    ])

    # Rotation around Y (yaw, horizontal turn right)
    Ry = np.array([
        [math.cos(yaw), 0, math.sin(yaw)],
        [0, 1, 0],
        [-math.sin(yaw), 0, math.cos(yaw)]
    ])

    ray_world = Ry @ (Rx @ ray)

    # Step 4: Intersect ray with ground plane at Z = 0
    origin = np.array([0.0, 0.0, CAMERA_HEIGHT])
    dz = ray_world[2]
    t = CAMERA_HEIGHT / dz * -1
    point = origin + t * ray_world
    # Step 5: Rotate point back to camera-forward axis (undo yaw)
    # So X=left/right relative to camera forward, Y=forward
    yaw_matrix_inv = np.array([
        [math.cos(-yaw), 0, math.sin(-yaw)],
        [0, 1, 0],
        [-math.sin(-yaw), 0, math.cos(-yaw)]
    ])
    corrected_point = yaw_matrix_inv @ point

    X_corrected = corrected_point[0]
    Y_corrected = corrected_point[1]
    return [X_corrected, Y_corrected]


def calculate_angle(contour):
    if len(contour) < 5:
        return 0
    (x, y), (MA, ma), angle = cv2.fitEllipse(contour)
    return angle

def draw_info(image, color, angle, center, centerx, centery, index, area):
    cv2.putText(image, f"#{index}: {color}", (center[0] - 40, center[1] - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    cv2.putText(image, f"Angle: {angle:.2f}", (center[0] - 40, center[1] - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    cv2.putText(image, f"Center: {centerx:.2f} {centery:.2f}", (center[0] - 40, center[1] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    cv2.circle(image, center, 5, (0, 255, 0), -1)
    cv2.line(image, center, (int(center[0] + 50 * math.cos(math.radians(90 - angle))), 
                             int(center[1] - 50 * math.sin(math.radians(90 - angle)))), (0, 255, 0), 2)

def separate_touching_contours(contour, min_area_ratio=2):
    x, y, w, h = cv2.boundingRect(contour)
    mask = np.zeros((h, w), dtype=np.uint8)
    shifted_contour = contour - [x, y]
    cv2.drawContours(mask, [shifted_contour], -1, 255, -1)

    original_area = cv2.contourArea(contour)
    max_contours = []
    max_count = 1

    dist_transform = cv2.distanceTransform(mask, cv2.DIST_L2, 3)

    for threshold in np.linspace(0.1, 0.9, 9):
        _, thresh = cv2.threshold(dist_transform, threshold * dist_transform.max(), 255, 0)
        thresh = np.uint8(thresh)

        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        valid_contours = [c for c in contours if cv2.contourArea(c) > original_area * min_area_ratio]

        if len(valid_contours) > max_count:
            max_count = len(valid_contours)
            max_contours = valid_contours

    if max_contours:
        return [c + [x, y] for c in max_contours]
    return [contour]

def pipeline_debug_return(frame):
    return None, None, None, True, frame

def process_color(frame, mask):
    debug_info = None
    #return pipeline_debug_return(frame)
    kernel = np.ones((5, 5), np.uint8)
    masked_frame = cv2.bitwise_and(frame, frame, mask=mask)  if 1 else frame
    #return pipeline_debug_return(masked_frame)
    gray_masked = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)  if 1 else masked_frame
    #return pipeline_debug_return(gray_masked)
    gray_boosted = cv2.addWeighted(gray_masked, 1.5, mask, 0.5, 0)  if 0 else gray_masked
    #return pipeline_debug_return(gray_boosted)
    blurred = cv2.GaussianBlur(gray_boosted, (3, 3), 0) if 1 else gray_boosted
    #return pipeline_debug_return(blurred)

    sobelx = cv2.Sobel(blurred, cv2.CV_32F, 1, 0, ksize=1)
    sobely = cv2.Sobel(blurred, cv2.CV_32F, 0, 1, ksize=1)

    magnitude = np.sqrt(sobelx**2 + sobely**2)
    magnitude = np.uint8(magnitude * 255 / np.max(magnitude))
    #return pipeline_debug_return(magnitude)

    _, edges = cv2.threshold(magnitude, 50, 255, cv2.THRESH_BINARY) if 1 else magnitude
    #return pipeline_debug_return(edges)

    #return pipeline_debug_return(edges)
    #return pipeline_debug_return(edges)
    edges = cv2.bitwise_not(edges) if 1 else edges
    #return pipeline_debug_return(edges)
    edges = cv2.bitwise_and(edges, edges, mask=mask) if 1 else edges
    #return pipeline_debug_return(edges)
    edges = cv2.GaussianBlur(edges, (3, 3), 0) if 1 else edges
    #return pipeline_debug_return(edges)
    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    return contours, hierarchy, gray_masked, False, debug_info


def debug_return(frame):
    return np.array([[]]), frame, [0, 0, 0, 0, 0, 0, 0, 0]


def runPipeline(frame, llrobot):
    try:
        # Initialize Limelight-style output
        llpython = [0, 0, 0, 0, 0, 0, 0, 0]
        largest_contour = np.array([[]])
        largest_area = 0
        
        # Convert to HSV and denoise
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        #cv2.imshow('1. HSV', hsv)
        
        hsv_denoised = cv2.GaussianBlur(hsv, (5, 5), 0)
        #cv2.imshow('2. HSV Denoised', hsv_denoised)
        hsv_denoised = hsv
        # Create mask for red (combining both ranges)
        red_mask1 = cv2.inRange(hsv_denoised, np.array(HSV_RED_RANGE_1[0]), np.array(HSV_RED_RANGE_1[1]))
        red_mask2 = cv2.inRange(hsv_denoised, np.array(HSV_RED_RANGE_2[0]), np.array(HSV_RED_RANGE_2[1]))
        red_mask = cv2.bitwise_or(red_mask1, red_mask2)
        red_mask = cv2.erode(red_mask, np.ones((3, 3), np.uint8))

        #cv2.imshow('3. Red Mask', red_mask)
        #return debug_return(red_mask)
        # Process red color
        red_contours, red_hierarchy, red_gray, isDebug, debug_info = process_color(frame, red_mask)
        if isDebug:
            return debug_return(debug_info)

        # Create a copy for contour visualization
        contour_frame = frame.copy()
        valid_contours = []
        #cv2.drawContours(frame, red_contours, -1, (0, 0, 255), 2)
        for i, contour in enumerate(red_contours):
            if cv2.contourArea(contour) < SMALL_CONTOUR_AREA:
                continue

            # Check aspect ratio using minAreaRect
            rect = cv2.minAreaRect(contour)
            width = max(rect[1])
            height = min(rect[1])
            if width == 0 or height == 0:
                continue
                
            aspect_ratio = width / height
            if aspect_ratio < MIN_ASPECT_RATIO or aspect_ratio > MAX_ASPECT_RATIO:
                continue

            for sep_contour in separate_touching_contours(contour):
                mask = np.zeros(red_gray.shape, dtype=np.uint8)
                cv2.drawContours(mask, [sep_contour], -1, 255, -1)
                #cv2.imshow('14. Contour Mask', mask)

                if cv2.mean(red_gray, mask=mask)[0] < MIN_BRIGHTNESS_THRESHOLD:
                    continue

                M = cv2.moments(sep_contour)
                if M["m00"] == 0:
                    continue

                center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
                angle = calculate_angle(sep_contour)
                area = cv2.contourArea(sep_contour)
                if area > 80000 :
                    continue
                

                # Store valid contour info
                valid_contours.append({
                    'contour': sep_contour,
                    'center': center,
                    'angle': angle,
                    'area': area,
                    'index': i
                })
                tx = (center[0])/78 - 4.5
                ty = ((center[1])/78 - 3.3) ** 1.9
                total = abs(tx) + abs(ty)
                oldtx = (llpython[1])/78 - 4.5
                oldty = ((llpython[2])/78 - 3.3) ** 1.9
                oldtotal = abs(oldtx) + abs(oldty)
                

                # Update llpython and largest_contour if this is the largest valid contour
        newpython = []
        servolist = []
        for contour_info in valid_contours:
            place = 0
            newercenter = [contour_info['center'][1],contour_info['center'][0]]
            thingy = [newercenter[1],  newercenter[0], contour_info['angle']]
            ground_coords = pixel_to_ground_coords(thingy[0], thingy[1])
            ground_coords[1] = ground_coords[1] + Camera_yOffset
            ground_coords[0] = ground_coords[0] + Camera_xOffset
            thingy = [ground_coords[0], ground_coords[1], contour_info['angle']]
            try:
                for i in newpython:
                    if i[1] < thingy[1]:
                        place += 1
                    else:
                        break
                if ground_coords[1] >= Min_y and ground_coords[1] <= Max_y and ground_coords[0] <= Max_x and ground_coords[0] >= Min_x:
                    newpython.insert(int(place), thingy)
            except Exception as e:
                newpython.insert(int(place), thingy)

            if ground_coords[1] >= Min_y and ground_coords[1] <= Max_y and ground_coords[0] <= Max_x and ground_coords[0] >= Min_x:
                cv2.drawContours(frame, [contour_info['contour']], -1, (0, 255, 0), 2)
                draw_info(frame, "Block", thingy[3], contour_info['center'], ground_coords[0], ground_coords[1], 
                        contour_info['index'] + 1, contour_info['area'])

        #cv2.imshow('15. Contours', contour_frame)
        #cv2.imshow('16. Final Output', frame)
        newerpython = []
        for i in newpython:
            newerpython.append(i[0])
            newerpython.append(i[1])
            newerpython.append(i[2])
    
        return largest_contour, frame, newerpython

    except Exception as e:
        print(f"Error: {str(e)}")
        return np.array([[]]), frame, [0, 0, 0, 0, 0, 0, 0, 0]
